{
	"batch_size": 16,
	"gamma": 0.99,
	"lr": 1e-3,
	"save_dir": "save",
	"log_dir": "log",
	"save_per_epoch": 5,
	"training_iter": 1,
	"training_batch_iter": 5,
	"h_dim": 100,
	"hv_dim": 50,
	"memory_size": 5000,
	"epsilon_spec": {
		"start": 0.1,
		"end": 0.0,
		"end_epoch": 200
	},
	"load": "save/best",
	"vocab_size": 500
}
